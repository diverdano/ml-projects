{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dan's Machine Learning Notes\n",
    "Here is the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pattern recognition, information retrieval and binary classification\n",
    "\n",
    "# Binary Classification\n",
    "\n",
    "Hypothesis: list of inputs predict if a student will pass\n",
    "null hypothesis: list of inputs do not predict if a student will pass\n",
    "This null hypothesis is tested against experimental data with a view to nullifying it with evidence to the contrary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score Distribution - Statistical testing\n",
    "from: https://en.wikipedia.org/wiki/Type_I_and_type_II_errors<br>\n",
    "There are four possbile outcomes\n",
    "Tabularised relations between truth/falseness of the null hypothesis and outcomes of the test:\n",
    "\n",
    "<table><tbody>\n",
    "    <tr>\n",
    "        <th rowspan=\"2\" colspan=\"2\">&nbsp;Table of error types</th>\n",
    "        <th colspan=\"2\">Null hypothesis (<i>H</i><sub>0</sub>) is</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>True</th>\n",
    "        <th>False</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th rowspan=\"2\">Decision About Null Hypothesis (<i>H</i><sub>0</sub>)</th>\n",
    "        <th>Reject</th>\n",
    "        <td style=\"text-align:center;\">Type&nbsp;I error (False Positive)</td>\n",
    "        <td style=\"text-align:center;\">Correct inference (True Positive)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>Fail to reject</th>\n",
    "        <td style=\"text-align:center;\">Correct inference (True Negative)</td>\n",
    "        <td style=\"text-align:center;\">Type&nbsp;II error (False Negative)</td>\n",
    "    </tr>\n",
    "</tbody></table>\n",
    "\n",
    "<ol>\n",
    "    <li>true positive - reject null hypothesis (null hypothesis is false)\n",
    "    <li>false positive - aka: type I error (incorrect rejection of null hypothesis)\n",
    "    <li>true negative - accept the null hypothesis (null hypothesis is true) \n",
    "    <li>false negative - aka: type II error (incorrect retaining a false null hypothesis)\n",
    "</ol>\n",
    "from: https://en.wikipedia.org/wiki/Precision_and_recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Measures of Relevance\n",
    "In pattern recognition, information retrieval and binary classification, precision (also called positive predictive value) = fraction of relevant instances among the retrieved instances, while recall (also known as sensitivity) is the fraction of relevant instances that have been retrieved over the total amount of relevant instances. Both precision and recall are therefore based on an understanding and measure of relevance.\n",
    "\n",
    "$Precision = \\frac{true\\ positives}{predicted\\ postives}\\\n",
    "     = how\\ many\\ selected\\ instances\\ are\\ relevant\\ (aka\\ positive\\ predictive\\ value)$\n",
    "\n",
    "$Recall = \\frac{true\\ positives}{condition\\ positive}\\\n",
    "    = \\frac{relevant\\ instances\\ retrieved}{all\\ relevant\\ instances}\\\n",
    "    = how\\ many\\ relevant\\ instances\\ are\\ selected\\ (aka\\ sensitivity)$\n",
    "\n",
    "$F_1\\ score = 2* \\frac{precision * recall}{precision + recall}\\\n",
    "    = harmonic\\ mean$\n",
    "\n",
    "$Accuracy = fraction\\ of\\ correct\\ predictions$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models\n",
    "\n",
    "### Gaussian Naive Bayes (GaussianNB)\n",
    "\n",
    "### Decision Trees\n",
    "\n",
    "### Ensemble Methods (Bagging, AdaBoost, Random Forest, Gradient Boosting)\n",
    "### K-Nearest Neighbors (KNeighbors)\n",
    "### Stochastic Gradient Descent (SGDC)\n",
    "### Support Vector Machines (SVM)\n",
    "### Logistic Regression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, VotingClassifier # need gradient boosting\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Plot Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [anaconda3]",
   "language": "python",
   "name": "Python [anaconda3]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
